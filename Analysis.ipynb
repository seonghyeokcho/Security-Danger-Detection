{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly.graph_objs import Scatter, Line, Layout, Bar\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from time import sleep\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 메모리 과부하 걸림 tlqkf\n",
    "'''## plotly.express 사용, 10시간 단위로 프로세스 관찰\n",
    "def visualization(x,col,P_value):\n",
    "    # 프로세스 값들을 0 ~ 1 사이로 스케일링 작업\n",
    "    scaler = MinMaxScaler()\n",
    "    x[x.columns[1:-4]] = scaler.fit_transform(x[x.columns[1:-4]])\n",
    "\n",
    "    #for col in x.filter(like=P_value[-2:] + \"_\").columns:\n",
    "    for i in range(len(x)//36000):  # 관찰 시간을 10시간으로 나누어서 시각화\n",
    "        extract = x[['time', col, P_value]].iloc[36000*i:36000*(i+1)]\n",
    "        melted = extract.melt(id_vars=['time'], value_vars=[col,P_value], var_name='process', value_name='condition')\n",
    "        fig = px.line(melted, x=\"time\", y=\"condition\", color=\"process\")\n",
    "        #fig.update_layout(height=450, width=280*40, title_text=\"{} operating 81 hours\".format(col))\n",
    "        fig.update_layout(hovermode='x unified', updatemenus=[dict(type = \"buttons\", direction = \"left\", buttons=list([dict(args=[{\"yaxis.type\": \"linear\"}], label=\"LINEAR\", method=\"relayout\"), dict(args=[{\"yaxis.type\": \"log\"}], label=\"LOG\", method=\"relayout\")]))], height=600, width=1200, title_text=\"{} operating {}/{} hours\".format(col,10*(i+1),len(x)//3600))\n",
    "        fig.show()\n",
    "        sleep(10)\n",
    "    return'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TaPR_pkg import etapr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset1 = pd.read_csv('data/HAI 2.0/training/train1.csv')\n",
    "trainset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset2 = pd.read_csv('data/HAI 2.0/training/train2.csv')\n",
    "trainset2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset3 = pd.read_csv('data/HAI 2.0/training/train3.csv')\n",
    "trainset3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validset = pd.read_csv('data/HAI 2.0/validation/validation.csv')\n",
    "validset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "same = (validset.max() == validset.min()).to_frame()\n",
    "list(same[same[0] == 1].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "validset[validset.columns[1:-1]] = scaler.fit_transform(validset[validset.columns[1:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validset[list(same[same[0] == 1].index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validset[list(same[same[0] == 1].index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = validset.corr()\n",
    "corr.attack.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## matplotlib.pyplot 을 사용해서 시각화\n",
    "def visualization(x, col, P_value):\n",
    "    # 프로세스 값들을 0 ~ 1 사이로 스케일링 작업\n",
    "    scaler = MinMaxScaler()\n",
    "    x[x.columns[1:-1]] = scaler.fit_transform(x[x.columns[1:-1]])\n",
    "\n",
    "    font = {'family':'AppleGothic',\n",
    "            'color':'steelblue',\n",
    "            'size':20}\n",
    "\n",
    "    for i in range(len(x)//10800):  # 관찰 시간을 3시간으로 나누어서 시각화\n",
    "        plt.figure(figsize=(20,12))\n",
    "        plt.title(\"{} operating each 3 hours\".format(col), fontdict=font)\n",
    "        plt.ylim(-0.01,1.01)\n",
    "        plt.plot(x[col].iloc[10800*i:10800*(i+1)], label='{}'.format(col), alpha=.7)\n",
    "        plt.plot(x[P_value].iloc[10800*i:10800*(i+1)], 'r:', linewidth=2)\n",
    "        plt.legend()\n",
    "        plt.ylabel(\"condition\", fontdict=font)\n",
    "        plt.xlabel(\"time (sec)\", fontdict=font)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization(validset, 'C01', 'attack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyculiarity import detect_ts\n",
    "from pyculiarity.date_utils import date_format\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_ts(inDF, y,  savepath ):\n",
    "    fig = plt.figure(figsize = (22,12))\n",
    "\n",
    "    plt.plot(inDF.index, inDF[y], alpha = 0.4, label = y)\n",
    "    plt.legend(); plt.xlabel('time'); plt.ylabel(y)\n",
    "#     plt.savefig(savepath, dpi = 300); plt.close()\n",
    "\n",
    "def plot_ts_anoms(inDF, savepath):\n",
    "    fig = plt.figure(figsize = (22,12))\n",
    "    #plt.ylim(-0.01,1.01)\n",
    "    plt.plot(inDF.index, inDF['value'], alpha=0.4, label ='value')\n",
    "    plt.plot(inDF.index, inDF['anoms'],  color='steelblue', alpha=0.4, marker='o', markersize='7',\n",
    "                markeredgewidth = 1, markerfacecolor='None', markeredgecolor='red',label='anomalies')\n",
    "    if 'expected_value' in inDF.columns:\n",
    "        plt.plot(inDF.index, inDF['expected_value'], color = 'c', marker = '^', markersize = '7',\n",
    "                 markeredgewidth = 1, markerfacecolor='None', markeredgecolor='c',label='expected_value')\n",
    "\n",
    "    plt.legend(); plt.xlabel('time');plt.ylabel('value')\n",
    "#     plt.savefig(savepath, dpi = 300); plt.close()\n",
    "\n",
    "\"\"\" Plotting \"\"\"\n",
    "# reformat the index and columns\n",
    "timeS_DF = validset[['C01','attack']]\n",
    "\n",
    "anomsDF = timeS_DF[timeS_DF.attack == 1]['C01'].to_frame()\n",
    "anomsDF.columns = [\"anoms\"]\n",
    "anomsDF['is_anom'] = True\n",
    "# anomsDF.columns = ['anom_value','is_anom']\n",
    "\n",
    "timeS_DF.drop('attack', axis=1, inplace=True)\n",
    "timeS_DF.columns = [\"value\"]\n",
    "\n",
    "merged_DF = pd.merge(left = timeS_DF, right= anomsDF, left_index=True, right_index=True, how = 'left')\n",
    "# merged_DF.drop('anom_value',axis = 1,inplace=True)\n",
    "\n",
    "\"\"\" Deliverables \"\"\"\n",
    "print('>>> the number of anomaly: ', len(anomsDF))\n",
    "\n",
    "# plot_ts(timeS_DF, 'value', './figures/orig_%s.png' % n_file ) # original data\n",
    "plot_ts_anoms(merged_DF,'./void') # anoms marked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MAD와 generalized ESD로 S-H-ESD 기능을 구현한 부분\n",
    "for i in range(1, max_outliers + 1):\n",
    "        if one_tail:\n",
    "            if upper_tail:\n",
    "                ares = data.value - data.value.median()\n",
    "            else:\n",
    "                ares = data.value.median() - data.value\n",
    "        else:\n",
    "            ares = (data.value - data.value.median()).abs()        \n",
    "        data_sigma = mad(data.value)\n",
    "\n",
    "        if data_sigma == 0:\n",
    "            break\n",
    "\n",
    "        ares = ares/float(data_sigma)\n",
    "        R = ares.max()\n",
    "        temp_max_idx = ares[ares == R].index.tolist()[0]\n",
    "        R_idx[i - 1] = temp_max_idx\n",
    "        data = data[data.index != R_idx[i - 1]]\n",
    "        if one_tail:\n",
    "            p = 1 - alpha / float(n - i + 1)\n",
    "        else:\n",
    "            p = 1 - alpha / float(2 * (n - i + 1))\n",
    "        t = student_t.ppf(p, (n - i - 1))\n",
    "        lam = t * (n - i) / float(sqrt((n - i - 1 + t**2) * (n - i + 1)))\n",
    "\n",
    "    if R > lam:\n",
    "        num_anoms = i"
   ]
  }
 ]
}